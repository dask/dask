language: generic
sudo: false
dist: trusty
os: linux

_base_envs:
  - &test_and_lint TEST='true' LINT='true'
  - &coverage COVERAGE='true' PARALLEL='false'
  - &no_coverage COVERAGE='false' PARALLEL='true'
  - &optimize PYTHONOPTIMIZE=2 XTRATESTARGS='--ignore=dask/diagnostics --ignore=dask/array/tests/test_image.py --ignore=dask/array/tests/test_stats.py'
  - &no_optimize XTRATESTARGS=
  - &imports TEST_IMPORTS='true'
  - &no_imports TEST_IMPORTS='false'

jobs:
  fast_finish: true
  include:
    - env:
      - PYTHON=2.7
      - NUMPY=1.14.1
      - PANDAS=0.22.0
      - *test_and_lint
      - *no_coverage
      - *no_optimize
      - *no_imports

    - env:
      - PYTHON=2.7
      - NUMPY=1.13.0
      - PANDAS=0.20.2
      - *test_and_lint
      - *no_coverage
      - *optimize
      - *no_imports

    - env:
      - PYTHON=3.4
      - NUMPY=1.11.3
      - PANDAS=0.19.1
      - *test_and_lint
      - *no_coverage
      - *optimize
      - *no_imports
      if: type != pull_request

    - env:
      - PYTHON=3.5
      - NUMPY=1.11.1
      - PANDAS=0.19.2
      - *test_and_lint
      - *no_coverage
      - *no_optimize
      - *no_imports

    - env: &py36_env
      - PYTHON=3.6
      - NUMPY=1.14.1
      - PANDAS=0.22.0
      - *test_and_lint
      - *coverage
      - *no_optimize
      - *imports

    - env: &py36_dev
      - UPSTREAM_DEV=1  # Install nightly versions of NumPy, pandas, pyarrow
      - NUMPY=1.13.0    # these are overridden later
      - PANDAS=0.20.3
      - *test_and_lint
      - *no_coverage
      - *no_optimize
      - *no_imports
      if: type != pull_request

    - env: *py36_env
      if: type != pull_request
      os: osx

    - env:
      - TEST_HDFS='true'
      if: type != pull_request OR head_branch =~ __TEST_HDFS__  # Skip on PRS unless the branch contains __TEST_HDFS__
      sudo: true
      services:
        - docker
      before_install:
        - source continuous_integration/hdfs/startup_hdfs.sh

  allow_failures:
    - env: *py36_dev
    - os: osx


install:
  - if [[ $TEST_HDFS == 'true' ]]; then source continuous_integration/hdfs/install.sh; fi
  - if [[ $TEST == 'true' ]]; then source continuous_integration/travis/install.sh; fi
  - mkdir -p $HOME/bin
  - if [[ "${TRAVIS_OS_NAME}" = "osx" ]]; then
      curl -fsSL https://testspace-client.s3.amazonaws.com/testspace-darwin.tgz | tar -zxvf- -C $HOME/bin;
    else
      curl -fsSL https://testspace-client.s3.amazonaws.com/testspace-linux.tgz | tar -zxvf- -C $HOME/bin;
    fi
  - testspace config url $TS_ORG.testspace.com

script:
  - if [[ $TEST_HDFS == 'true' ]]; then source continuous_integration/hdfs/run_tests.sh; fi
  - if [[ $TEST == 'true' ]]; then source continuous_integration/travis/run_tests.sh; fi
  - if [[ $LINT == 'true' ]]; then flake8 dask; fi
  - if [[ $TEST_IMPORTS == 'true' ]]; then source continuous_integration/travis/test_imports.sh; fi

after_script:
  - ${TRAVIS_ALLOW_FAILURE} || if [[ $TEST_HDFS == 'true' ]]; then
      docker cp $CONTAINER_ID:/working/testresults.xml $TRAVIS_BUILD_DIR/testresults.xml;
      testspace [hdfs]testresults.xml{.};
    elif [[ $UPSTREAM_DEV == 1 ]]; then
      testspace [upstream-dev]testresults.xml{.} --link=coveralls;
    else
      testspace [py-${PYTHON}-numpy-${NUMPY}]testresults.xml{.} --link=coveralls;
    fi

after_success:
  - source continuous_integration/travis/after_success.sh

notifications:
  email: false
